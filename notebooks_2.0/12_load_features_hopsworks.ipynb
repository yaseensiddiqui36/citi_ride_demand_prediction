{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4e148a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Loading Citi Bike data for the last 13 months\n",
      "⬇️ Downloading https://s3.amazonaws.com/tripdata/JC-202505-citibike-tripdata.csv.zip\n",
      "⚠️ Failed to fetch https://s3.amazonaws.com/tripdata/JC-202505-citibike-tripdata.csv.zip (status 404), skipping.\n",
      "📁 Already exists: ..\\data\\raw\\JC-202504-citibike-tripdata.csv\n",
      "Processing: JC-202504-citibike-tripdata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yaseen\\Desktop\\courses\\UB\\Spring25\\CDA500\\sp25_citi_bike-main\\src\\data_utils.py:257: UserWarning: Parsing dates in %Y-%m-%d %H:%M:%S.%f format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  df[\"started_at\"] = pd.to_datetime(df[\"started_at\"], errors='coerce', dayfirst=True)\n",
      "c:\\Users\\Yaseen\\Desktop\\courses\\UB\\Spring25\\CDA500\\sp25_citi_bike-main\\src\\data_utils.py:258: UserWarning: Parsing dates in %Y-%m-%d %H:%M:%S.%f format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  df[\"ended_at\"] = pd.to_datetime(df[\"ended_at\"], errors='coerce', dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved: ..\\data\\processed\\rides_2025_04.parquet\n",
      "📁 Already exists: ..\\data\\raw\\JC-202503-citibike-tripdata.csv\n",
      "Processing: JC-202503-citibike-tripdata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yaseen\\Desktop\\courses\\UB\\Spring25\\CDA500\\sp25_citi_bike-main\\src\\data_utils.py:257: UserWarning: Parsing dates in %Y-%m-%d %H:%M:%S.%f format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  df[\"started_at\"] = pd.to_datetime(df[\"started_at\"], errors='coerce', dayfirst=True)\n",
      "c:\\Users\\Yaseen\\Desktop\\courses\\UB\\Spring25\\CDA500\\sp25_citi_bike-main\\src\\data_utils.py:258: UserWarning: Parsing dates in %Y-%m-%d %H:%M:%S.%f format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  df[\"ended_at\"] = pd.to_datetime(df[\"ended_at\"], errors='coerce', dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved: ..\\data\\processed\\rides_2025_03.parquet\n",
      "📁 Already exists: ..\\data\\raw\\JC-202502-citibike-tripdata.csv\n",
      "Processing: JC-202502-citibike-tripdata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yaseen\\Desktop\\courses\\UB\\Spring25\\CDA500\\sp25_citi_bike-main\\src\\data_utils.py:257: UserWarning: Parsing dates in %Y-%m-%d %H:%M:%S.%f format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  df[\"started_at\"] = pd.to_datetime(df[\"started_at\"], errors='coerce', dayfirst=True)\n",
      "c:\\Users\\Yaseen\\Desktop\\courses\\UB\\Spring25\\CDA500\\sp25_citi_bike-main\\src\\data_utils.py:258: UserWarning: Parsing dates in %Y-%m-%d %H:%M:%S.%f format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  df[\"ended_at\"] = pd.to_datetime(df[\"ended_at\"], errors='coerce', dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved: ..\\data\\processed\\rides_2025_02.parquet\n",
      "📁 Already exists: ..\\data\\raw\\JC-202501-citibike-tripdata.csv\n",
      "Processing: JC-202501-citibike-tripdata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yaseen\\Desktop\\courses\\UB\\Spring25\\CDA500\\sp25_citi_bike-main\\src\\data_utils.py:257: UserWarning: Parsing dates in %Y-%m-%d %H:%M:%S.%f format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  df[\"started_at\"] = pd.to_datetime(df[\"started_at\"], errors='coerce', dayfirst=True)\n",
      "c:\\Users\\Yaseen\\Desktop\\courses\\UB\\Spring25\\CDA500\\sp25_citi_bike-main\\src\\data_utils.py:258: UserWarning: Parsing dates in %Y-%m-%d %H:%M:%S.%f format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  df[\"ended_at\"] = pd.to_datetime(df[\"ended_at\"], errors='coerce', dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved: ..\\data\\processed\\rides_2025_01.parquet\n",
      "📁 Already exists: ..\\data\\raw\\JC-202412-citibike-tripdata.csv\n",
      "Processing: JC-202412-citibike-tripdata.csv\n",
      "💾 Saved: ..\\data\\processed\\rides_2024_12.parquet\n",
      "📁 Already exists: ..\\data\\raw\\JC-202411-citibike-tripdata.csv\n",
      "Processing: JC-202411-citibike-tripdata.csv\n",
      "💾 Saved: ..\\data\\processed\\rides_2024_11.parquet\n",
      "📁 Already exists: ..\\data\\raw\\JC-202410-citibike-tripdata.csv\n",
      "Processing: JC-202410-citibike-tripdata.csv\n",
      "💾 Saved: ..\\data\\processed\\rides_2024_10.parquet\n",
      "📁 Already exists: ..\\data\\raw\\JC-202409-citibike-tripdata.csv\n",
      "Processing: JC-202409-citibike-tripdata.csv\n",
      "💾 Saved: ..\\data\\processed\\rides_2024_09.parquet\n",
      "📁 Already exists: ..\\data\\raw\\JC-202408-citibike-tripdata.csv\n",
      "Processing: JC-202408-citibike-tripdata.csv\n",
      "💾 Saved: ..\\data\\processed\\rides_2024_08.parquet\n",
      "📁 Already exists: ..\\data\\raw\\JC-202407-citibike-tripdata.csv\n",
      "Processing: JC-202407-citibike-tripdata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yaseen\\Desktop\\courses\\UB\\Spring25\\CDA500\\sp25_citi_bike-main\\src\\data_utils.py:257: UserWarning: Parsing dates in %Y-%m-%d %H:%M:%S.%f format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  df[\"started_at\"] = pd.to_datetime(df[\"started_at\"], errors='coerce', dayfirst=True)\n",
      "c:\\Users\\Yaseen\\Desktop\\courses\\UB\\Spring25\\CDA500\\sp25_citi_bike-main\\src\\data_utils.py:258: UserWarning: Parsing dates in %Y-%m-%d %H:%M:%S.%f format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  df[\"ended_at\"] = pd.to_datetime(df[\"ended_at\"], errors='coerce', dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved: ..\\data\\processed\\rides_2024_07.parquet\n",
      "📁 Already exists: ..\\data\\raw\\JC-202406-citibike-tripdata.csv\n",
      "Processing: JC-202406-citibike-tripdata.csv\n",
      "💾 Saved: ..\\data\\processed\\rides_2024_06.parquet\n",
      "📁 Already exists: ..\\data\\raw\\JC-202405-citibike-tripdata.csv\n",
      "Processing: JC-202405-citibike-tripdata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yaseen\\Desktop\\courses\\UB\\Spring25\\CDA500\\sp25_citi_bike-main\\src\\data_utils.py:257: UserWarning: Parsing dates in %Y-%m-%d %H:%M:%S format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  df[\"started_at\"] = pd.to_datetime(df[\"started_at\"], errors='coerce', dayfirst=True)\n",
      "c:\\Users\\Yaseen\\Desktop\\courses\\UB\\Spring25\\CDA500\\sp25_citi_bike-main\\src\\data_utils.py:258: UserWarning: Parsing dates in %Y-%m-%d %H:%M:%S format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  df[\"ended_at\"] = pd.to_datetime(df[\"ended_at\"], errors='coerce', dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved: ..\\data\\processed\\rides_2024_05.parquet\n",
      "\n",
      "✅ Combined all data: 1,051,856 rows\n",
      "✅ Citi Bike ride data loaded: (1051856, 13)\n",
      "'rides' DataFrame created with 177154 rows from the top 5 most common start stations.\n",
      "✅ Transformed to time-series format: (57720, 3)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57720 entries, 0 to 57719\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   pickup_hour         57720 non-null  datetime64[ns]\n",
      " 1   pickup_location_id  57720 non-null  object        \n",
      " 2   rides               57720 non-null  int32         \n",
      "dtypes: datetime64[ns](1), int32(1), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from src.data_utils import load_and_process_citibike_data, transform_raw_data_into_ts_data\n",
    "\n",
    "# Load Citi Bike data for the last 13 months\n",
    "print(\"📦 Loading Citi Bike data for the last 13 months\")\n",
    "rides = load_and_process_citibike_data(months_back=13)\n",
    "print(\"✅ Citi Bike ride data loaded:\", rides.shape)\n",
    "\n",
    "#########################################################################\n",
    "\n",
    "processed_rides = rides.copy()\n",
    "# Get the 5 most common start_station_ids\n",
    "top_5_stations = processed_rides[\"start_station_id\"].value_counts().head(5).index\n",
    "# Filter the data to include only those 5 stations\n",
    "rides = processed_rides[processed_rides[\"start_station_id\"].isin(top_5_stations)].copy()\n",
    "\n",
    "print(f\"'rides' DataFrame created with {len(rides)} rows from the top 5 most common start stations.\")\n",
    "rides.head()\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "# Rename columns to match expected time-series format\n",
    "rides.rename(columns={\n",
    "    \"start_station_id\": \"pickup_location_id\",\n",
    "    \"started_at\": \"pickup_datetime\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Transform to hourly time series\n",
    "ts_data = transform_raw_data_into_ts_data(rides)\n",
    "print(\"✅ Transformed to time-series format:\", ts_data.shape)\n",
    "ts_data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "026b7d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>rides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-06 00:00:00</td>\n",
       "      <td>HB101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-06 01:00:00</td>\n",
       "      <td>HB101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-06 02:00:00</td>\n",
       "      <td>HB101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-06 03:00:00</td>\n",
       "      <td>HB101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-06 04:00:00</td>\n",
       "      <td>HB101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pickup_hour pickup_location_id  rides\n",
       "0 2024-01-06 00:00:00              HB101      0\n",
       "1 2024-01-06 01:00:00              HB101      0\n",
       "2 2024-01-06 02:00:00              HB101      0\n",
       "3 2024-01-06 03:00:00              HB101      0\n",
       "4 2024-01-06 04:00:00              HB101      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f09784e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 10:05:20,203 INFO: Initializing external client\n",
      "2025-05-10 10:05:20,204 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.1.8 may not be compatible with the connected Hopsworks backend version 4.2.0. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 10:05:22,468 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1215665\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from src.data_utils import load_and_process_citibike_data, transform_raw_data_into_ts_data, load_and_process_citibike_data_local\n",
    "\n",
    "project = hopsworks.login()  # or hopsworks.login(api_key_value=\"your_api_key\")\n",
    "feature_store = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02adf82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 57720/57720 | Elapsed Time: 00:08 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: citibike_hourly_features_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1215665/jobs/named/citibike_hourly_features_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('citibike_hourly_features_1_offline_fg_materialization', 'SPARK'), None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from hsfs.feature import Feature\n",
    "# import hopsworks\n",
    "\n",
    "# features = [\n",
    "#     Feature(name=\"pickup_hour\", type=\"timestamp\"),\n",
    "#     Feature(name=\"pickup_location_id\", type=\"string\"),\n",
    "#     Feature(name=\"rides\", type=\"bigint\"),\n",
    "# ]\n",
    "\n",
    "# feature_group = feature_store.get_or_create_feature_group(\n",
    "#     name=\"citibike_hourly_features\",\n",
    "#     version=1,\n",
    "#     description=\"Time-series Citi Bike rides aggregated by hour and location\",\n",
    "#     primary_key=[\"pickup_location_id\", \"pickup_hour\"],\n",
    "#     event_time=\"pickup_hour\",\n",
    "#     features=features\n",
    "# )\n",
    "\n",
    "# feature_group.insert(ts_data, write_options={\"wait_for_job\": False})\n",
    "\n",
    "\n",
    "from hsfs.feature import Feature\n",
    "import numpy as np\n",
    "\n",
    "# Define the schema for the feature group\n",
    "features = [\n",
    "    Feature(name=\"pickup_hour\", type=\"timestamp\"),\n",
    "    Feature(name=\"pickup_location_id\", type=\"string\"),\n",
    "    Feature(name=\"rides\", type=\"bigint\"),\n",
    "]\n",
    "\n",
    "# Create or retrieve the feature group\n",
    "feature_group = feature_store.get_or_create_feature_group(\n",
    "    name=\"citibike_hourly_features\",\n",
    "    version=1,\n",
    "    description=\"Time-series Citi Bike rides aggregated by hour and location\",\n",
    "    primary_key=[\"pickup_location_id\", \"pickup_hour\"],\n",
    "    event_time=\"pickup_hour\",\n",
    "    features=features\n",
    ")\n",
    "\n",
    "# ✅ Ensure the 'rides' column has the correct dtype (int64 for 'bigint')\n",
    "ts_data[\"rides\"] = ts_data[\"rides\"].astype(np.int64)\n",
    "\n",
    "# Insert data into the feature group\n",
    "feature_group.insert(ts_data, write_options={\"wait_for_job\": False})\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7686467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.99s) \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>rides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-08-22 08:00:00+00:00</td>\n",
       "      <td>HB101</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-08-17 02:00:00+00:00</td>\n",
       "      <td>JC066</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-02-27 07:00:00+00:00</td>\n",
       "      <td>HB101</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-08 17:00:00+00:00</td>\n",
       "      <td>JC066</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-05-25 20:00:00+00:00</td>\n",
       "      <td>JC066</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pickup_hour pickup_location_id  rides\n",
       "0 2024-08-22 08:00:00+00:00              HB101     10\n",
       "1 2024-08-17 02:00:00+00:00              JC066      0\n",
       "2 2025-02-27 07:00:00+00:00              HB101      3\n",
       "3 2024-01-08 17:00:00+00:00              JC066     15\n",
       "4 2024-05-25 20:00:00+00:00              JC066     15"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the feature group (if not already loaded)\n",
    "feature_group = feature_store.get_feature_group(\n",
    "    name=\"citibike_hourly_features\",\n",
    "    version=1\n",
    ")\n",
    "\n",
    "# Read data from offline storage\n",
    "ts_data_from_hopsworks = feature_group.read()\n",
    "\n",
    "# Preview the data\n",
    "ts_data_from_hopsworks.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bf77978",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_utils import load_and_process_citibike_data_local\n",
    "from src.data_utils import transform_raw_data_into_ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3695cb85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 10:06:03,269 INFO: 📅 Loading Citi Bike data from local storage (last 13 months) …\n",
      "⚠️ No file found for 202505\n",
      "📂 Reading: JC-202504-citibike-tripdata.csv\n",
      "📂 Reading: JC-202503-citibike-tripdata.csv\n",
      "📂 Reading: JC-202502-citibike-tripdata.csv\n",
      "📂 Reading: JC-202501-citibike-tripdata.csv\n",
      "📂 Reading: JC-202412-citibike-tripdata.csv\n",
      "📂 Reading: JC-202411-citibike-tripdata.csv\n",
      "📂 Reading: JC-202410-citibike-tripdata.csv\n",
      "📂 Reading: JC-202409-citibike-tripdata.csv\n",
      "📂 Reading: JC-202408-citibike-tripdata.csv\n",
      "📂 Reading: JC-202407-citibike-tripdata.csv\n",
      "📂 Reading: JC-202406-citibike-tripdata.csv\n",
      "📂 Reading: JC-202405-citibike-tripdata.csv\n",
      "✅ Loaded and processed 12 months. Total records: 1,051,856\n",
      "2025-05-10 10:06:14,093 INFO: ✅ Loaded 1,051,856 rows of ride data.\n",
      "'rides' DataFrame created with 177154 rows from the top 5 most common start stations.\n",
      "2025-05-10 10:06:15,155 INFO: 🧮 Aggregating to hourly time-series format …\n",
      "2025-05-10 10:06:15,803 INFO: ✅ Transformed dataset shape: (43785, 3)\n",
      "2025-05-10 10:06:15,804 INFO: 🔐 Logging in to Hopsworks …\n",
      "2025-05-10 10:06:15,806 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-05-10 10:06:15,821 INFO: Initializing external client\n",
      "2025-05-10 10:06:15,822 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.1.8 may not be compatible with the connected Hopsworks backend version 4.2.0. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 10:06:17,115 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1215665\n",
      "2025-05-10 10:06:17,721 INFO: 📦 Writing to Hopsworks feature group …\n",
      "2025-05-10 10:06:17,962 INFO: ⏫ Uploading time-series data to Hopsworks …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 43785/43785 | Elapsed Time: 00:07 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 10:06:27,992 INFO: ✅ Upload complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Materialization job is already running, aborting new execution.Please wait for the current execution to finish before triggering a new one.You can check the status of the current execution using `fg.materialization_job.get_state()`.or `fg.materialization_job.get_final_state()` or check it out in the Hopsworks UI.at https://c.app.hopsworks.ai:443/p/1215665/jobs/named/citibike_hourly_features_1_offline_fg_materialization.\n",
      "Use fg.materialization_job.run(args=-op offline_fg_materialization -path hdfs:///Projects/ml_ops_project/Resources/jobs/citibike_hourly_features_1_offline_fg_materialization/config_1746872423754) to trigger the materialization job again.\n"
     ]
    }
   ],
   "source": [
    "# notebooks/create_full_feature_group.py\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add root path to sys.path (adjust if needed)\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "from hsfs.feature import Feature\n",
    "\n",
    "from src.data_utils import (\n",
    "    load_and_process_citibike_data_local,\n",
    "    transform_raw_data_into_ts_data,\n",
    ")\n",
    "import src.config as config\n",
    "\n",
    "# ─────────────────────────────────────────────────────\n",
    "# Logging setup\n",
    "# ─────────────────────────────────────────────────────\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s  %(levelname)s  %(message)s\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout)]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ─────────────────────────────────────────────────────\n",
    "# 1. Load raw Citi Bike data (last 13 months from local)\n",
    "# ─────────────────────────────────────────────────────\n",
    "logger.info(\"📅 Loading Citi Bike data from local storage (last 13 months) …\")\n",
    "raw_rides = load_and_process_citibike_data_local(\n",
    "    base_path=config.LOCAL_CITIBIKE_DATA_PATH,\n",
    "    months_back=13\n",
    ")\n",
    "logger.info(f\"✅ Loaded {len(raw_rides):,} rows of ride data.\")\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------#\n",
    "\n",
    "processed_rides = raw_rides.copy()\n",
    "# Get the 5 most common start_station_ids\n",
    "top_5_stations = processed_rides[\"start_station_id\"].value_counts().head(5).index\n",
    "# Filter the data to include only those 5 stations\n",
    "rides = processed_rides[processed_rides[\"start_station_id\"].isin(top_5_stations)].copy()\n",
    "\n",
    "print(f\"'rides' DataFrame created with {len(rides)} rows from the top 5 most common start stations.\")\n",
    "rides.head()\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------#\n",
    "\n",
    "# ─────────────────────────────────────────────────────\n",
    "# 2. Transform raw data into hourly time-series\n",
    "# ─────────────────────────────────────────────────────\n",
    "logger.info(\"🧮 Aggregating to hourly time-series format …\")\n",
    "ts_data = transform_raw_data_into_ts_data(rides)\n",
    "logger.info(f\"✅ Transformed dataset shape: {ts_data.shape}\")\n",
    "\n",
    "# ─────────────────────────────────────────────────────\n",
    "# 3. Log in to Hopsworks\n",
    "# ─────────────────────────────────────────────────────\n",
    "logger.info(\"🔐 Logging in to Hopsworks …\")\n",
    "# project = hopsworks.connection(\n",
    "#     # host=config.HOPSWORKS_HOST,\n",
    "#     project=config.HOPSWORKS_PROJECT_NAME,\n",
    "#     api_key_value=config.HOPSWORKS_API_KEY,\n",
    "# ).get_project()\n",
    "# fs = project.get_feature_store()\n",
    "\n",
    "\n",
    "project = hopsworks.login()  # or hopsworks.login(api_key_value=\"your_api_key\")\n",
    "fs = feature_store = project.get_feature_store()\n",
    "\n",
    "\n",
    "\n",
    "# ─────────────────────────────────────────────────────\n",
    "# 4. Define feature group schema\n",
    "# ─────────────────────────────────────────────────────\n",
    "fg_schema = [\n",
    "    Feature(\"pickup_hour\", \"timestamp\"),\n",
    "    Feature(\"pickup_location_id\", \"string\"),\n",
    "    Feature(\"rides\", \"bigint\"),  # bigint in Hopsworks = int64 in pandas\n",
    "]\n",
    "\n",
    "# ─────────────────────────────────────────────────────\n",
    "# 5. Create or retrieve the feature group\n",
    "# ─────────────────────────────────────────────────────\n",
    "logger.info(\"📦 Writing to Hopsworks feature group …\")\n",
    "hourly_fg = fs.get_or_create_feature_group(\n",
    "    name=\"citibike_hourly_features\",\n",
    "    version=1,\n",
    "    description=\"Hourly Citi Bike rides per location (last 13 months)\",\n",
    "    primary_key=[\"pickup_hour\", \"pickup_location_id\"],\n",
    "    event_time=\"pickup_hour\",\n",
    "    online_enabled=False,\n",
    "    features=fg_schema,\n",
    ")\n",
    "\n",
    "# ✅ Ensure types match schema\n",
    "ts_data[\"pickup_location_id\"] = ts_data[\"pickup_location_id\"].astype(str)\n",
    "ts_data[\"rides\"] = ts_data[\"rides\"].astype(\"int64\")\n",
    "\n",
    "# ─────────────────────────────────────────────────────\n",
    "# 6. Insert into Hopsworks feature store\n",
    "# ─────────────────────────────────────────────────────\n",
    "logger.info(\"⏫ Uploading time-series data to Hopsworks …\")\n",
    "hourly_fg.insert(ts_data, write_options={\"wait_for_job\": True})\n",
    "logger.info(\"✅ Upload complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8dfa44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67490f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
